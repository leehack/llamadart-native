name: Native Build & Release

on:
  workflow_dispatch:
    inputs:
      llama_cpp_tag:
        description: 'llama.cpp ref to build (e.g., b8011, latest, submodule)'
        required: true
        default: 'latest'
      publish_release:
        description: 'Publish GitHub release'
        required: true
        default: true
        type: boolean

permissions:
  contents: write

env:
  CMAKE_C_COMPILER_LAUNCHER: ccache
  CMAKE_CXX_COMPILER_LAUNCHER: ccache
  CMAKE_CUDA_COMPILER_LAUNCHER: ccache
  VCPKG_CACHE_VERSION: v1

jobs:
  resolve-tag:
    runs-on: ubuntu-latest
    outputs:
      tag: ${{ steps.tag.outputs.tag }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: recursive

      - name: Resolve llama.cpp tag
        id: tag
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          TAG="${{ github.event.inputs.llama_cpp_tag }}"

          if [ -z "$TAG" ] || [ "$TAG" = "latest" ]; then
            TAG=$(gh api repos/ggml-org/llama.cpp/releases/latest --jq '.tag_name')
          elif [ "$TAG" = "submodule" ]; then
            TAG=$(git -C third_party/llama.cpp describe --tags --exact-match 2>/dev/null || git -C third_party/llama.cpp rev-parse --short HEAD)
          fi

          echo "tag=$TAG" >> "$GITHUB_OUTPUT"
          echo "Resolved tag: $TAG"

  build-android:
    needs: resolve-tag
    runs-on: ubuntu-latest
    env:
      CCACHE_DIR: ${{ github.workspace }}/.ccache
      CCACHE_MAXSIZE: 2G
    strategy:
      fail-fast: false
      matrix:
        include:
          - android_abi: arm64-v8a
            out_arch: arm64
            backend: vulkan
            include_core: true
            backend_glob: libggml-vulkan.so
          - android_abi: arm64-v8a
            out_arch: arm64
            backend: opencl
            include_core: false
            backend_glob: libggml-opencl.so
          - android_abi: x86_64
            out_arch: x64
            backend: vulkan
            include_core: true
            backend_glob: libggml-vulkan.so
          - android_abi: x86_64
            out_arch: x64
            backend: opencl
            include_core: false
            backend_glob: libggml-opencl.so
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: recursive
      - name: Checkout llama.cpp ref
        if: ${{ github.event.inputs.llama_cpp_tag != 'submodule' }}
        uses: ./.github/actions/checkout-llama-ref
        with:
          tag: ${{ needs.resolve-tag.outputs.tag }}
          github_token: ${{ github.token }}
      - name: Set up JDK
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: '17'
      - name: Setup Android SDK/NDK
        uses: android-actions/setup-android@v3
      - name: Install build deps
        run: sudo apt-get update && sudo apt-get install -y ninja-build ccache
      - name: Restore ccache
        uses: actions/cache@v4
        with:
          path: ${{ env.CCACHE_DIR }}
          key: ccache-android-${{ matrix.android_abi }}-${{ github.run_id }}
          restore-keys: |
            ccache-android-${{ matrix.android_abi }}-
      - name: Prime ccache
        run: |
          mkdir -p "${CCACHE_DIR}"
          ccache --max-size "${CCACHE_MAXSIZE}"
          ccache --zero-stats
      - name: Build
        run: python3 tools/build.py android --abi ${{ matrix.android_abi }} --backend ${{ matrix.backend }}
      - name: ccache stats
        if: always()
        run: ccache --show-stats
      - name: Validate Android backend artifacts
        run: |
          OUT_DIR="bin/android/${{ matrix.out_arch }}"
          test -f "$OUT_DIR/${{ matrix.backend_glob }}" || { echo "Missing $OUT_DIR/${{ matrix.backend_glob }}"; exit 1; }
      - name: Stage upload payload
        run: |
          OUT_DIR="bin/android/${{ matrix.out_arch }}"
          PAYLOAD="artifact_payload"
          mkdir -p "$PAYLOAD"
          if [ "${{ matrix.include_core }}" = "true" ]; then
            cp "$OUT_DIR"/*.so "$PAYLOAD"/
          else
            cp "$OUT_DIR/${{ matrix.backend_glob }}" "$PAYLOAD"/
          fi
          ls -la "$PAYLOAD"
          test -n "$(find "$PAYLOAD" -maxdepth 1 -type f -print -quit)"
      - name: Upload
        uses: actions/upload-artifact@v4
        with:
          name: native_android_${{ matrix.android_abi }}_${{ matrix.backend }}
          path: artifact_payload/*

  build-apple:
    needs: resolve-tag
    runs-on: macos-latest
    env:
      CCACHE_DIR: ${{ github.workspace }}/.ccache
      CCACHE_MAXSIZE: 2G
    strategy:
      fail-fast: false
      matrix:
        include:
          - target: macos-arm64
            out_dir: macos/arm64
          - target: macos-x86_64
            out_dir: macos/x86_64
          - target: ios-device-arm64
            out_dir: ios/arm64
          - target: ios-sim-arm64
            out_dir: ios/arm64-sim
          - target: ios-sim-x86_64
            out_dir: ios/x86_64-sim
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: recursive
      - name: Checkout llama.cpp ref
        if: ${{ github.event.inputs.llama_cpp_tag != 'submodule' }}
        uses: ./.github/actions/checkout-llama-ref
        with:
          tag: ${{ needs.resolve-tag.outputs.tag }}
          github_token: ${{ github.token }}
      - name: Install build deps
        run: brew install ccache
      - name: Restore ccache
        uses: actions/cache@v4
        with:
          path: ${{ env.CCACHE_DIR }}
          key: ccache-apple-${{ matrix.target }}-${{ github.run_id }}
          restore-keys: |
            ccache-apple-${{ matrix.target }}-
      - name: Prime ccache
        run: |
          mkdir -p "${CCACHE_DIR}"
          ccache --max-size "${CCACHE_MAXSIZE}"
          ccache --zero-stats
      - name: Build
        run: python3 tools/build.py apple --target ${{ matrix.target }}
      - name: ccache stats
        if: always()
        run: ccache --show-stats
      - name: Upload
        uses: actions/upload-artifact@v4
        with:
          name: native_apple_${{ matrix.target }}
          path: bin/${{ matrix.out_dir }}/*

  build-linux:
    needs: resolve-tag
    runs-on: ubuntu-latest
    env:
      CCACHE_DIR: ${{ github.workspace }}/.ccache
      CCACHE_MAXSIZE: 5G
    strategy:
      fail-fast: false
      matrix:
        include:
          - arch: x64
            backend: vulkan
            include_core: true
            needs_vulkan: true
            needs_openblas: false
            needs_cuda: false
            backend_glob: libggml-vulkan.so
          - arch: x64
            backend: cuda
            include_core: false
            needs_vulkan: false
            needs_openblas: false
            needs_cuda: true
            backend_glob: libggml-cuda.so
          - arch: x64
            backend: blas
            include_core: false
            needs_vulkan: false
            needs_openblas: true
            needs_cuda: false
            backend_glob: libggml-blas.so
          - arch: arm64
            backend: vulkan
            include_core: true
            needs_vulkan: true
            needs_openblas: false
            needs_cuda: false
            backend_glob: libggml-vulkan.so
          - arch: arm64
            backend: blas
            include_core: false
            needs_vulkan: false
            needs_openblas: true
            needs_cuda: false
            backend_glob: libggml-blas.so
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: recursive
      - name: Checkout llama.cpp ref
        if: ${{ github.event.inputs.llama_cpp_tag != 'submodule' }}
        uses: ./.github/actions/checkout-llama-ref
        with:
          tag: ${{ needs.resolve-tag.outputs.tag }}
          github_token: ${{ github.token }}
      - name: Install build deps
        run: |
          if [ "${{ matrix.arch }}" = "arm64" ]; then
            sudo dpkg --add-architecture arm64
            source /etc/os-release
            CODENAME="${VERSION_CODENAME}"
            {
              printf '%s\n' \
                "Types: deb" \
                "URIs: http://archive.ubuntu.com/ubuntu" \
                "Suites: ${CODENAME} ${CODENAME}-updates ${CODENAME}-backports" \
                "Components: main universe restricted multiverse" \
                "Architectures: amd64" \
                "Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg" \
                "" \
                "Types: deb" \
                "URIs: http://security.ubuntu.com/ubuntu" \
                "Suites: ${CODENAME}-security" \
                "Components: main universe restricted multiverse" \
                "Architectures: amd64" \
                "Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg" \
                "" \
                "Types: deb" \
                "URIs: http://ports.ubuntu.com/ubuntu-ports" \
                "Suites: ${CODENAME} ${CODENAME}-updates ${CODENAME}-backports ${CODENAME}-security" \
                "Components: main universe restricted multiverse" \
                "Architectures: arm64" \
                "Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg"
            } | sudo tee /etc/apt/sources.list.d/ubuntu.sources >/dev/null
          fi
          sudo apt-get update
          sudo apt-get install -y ccache ninja-build pkg-config make
          if [ "${{ matrix.arch }}" = "arm64" ]; then
            sudo apt-get install -y gcc-aarch64-linux-gnu g++-aarch64-linux-gnu
          fi
          if [ "${{ matrix.needs_vulkan }}" = "true" ]; then
            sudo apt-get install -y libvulkan-dev glslc
            if [ "${{ matrix.arch }}" = "arm64" ]; then
              sudo apt-get install -y libvulkan-dev:arm64
            fi
          fi
          if [ "${{ matrix.needs_openblas }}" = "true" ]; then
            if [ "${{ matrix.arch }}" = "arm64" ]; then
              sudo apt-get install -y libopenblas-dev:arm64
            else
              sudo apt-get install -y libopenblas-dev
            fi
          fi
          if [ "${{ matrix.needs_cuda }}" = "true" ]; then
            sudo apt-get install -y nvidia-cuda-toolkit
          fi
      - name: Restore ccache
        uses: actions/cache@v4
        with:
          path: ${{ env.CCACHE_DIR }}
          key: ccache-linux-${{ matrix.arch }}-${{ github.run_id }}
          restore-keys: |
            ccache-linux-${{ matrix.arch }}-
      - name: Prime ccache
        run: |
          mkdir -p "${CCACHE_DIR}"
          ccache --max-size "${CCACHE_MAXSIZE}"
          ccache --zero-stats
      - name: Build
        run: python3 tools/build.py linux --arch "${{ matrix.arch }}" --backend "${{ matrix.backend }}"
      - name: ccache stats
        if: always()
        run: ccache --show-stats
      - name: Validate Linux backend artifacts
        run: |
          OUT_DIR="bin/linux/${{ matrix.arch }}"
          test -f "$OUT_DIR/${{ matrix.backend_glob }}" || { echo "Missing $OUT_DIR/${{ matrix.backend_glob }}"; exit 1; }
          if [ "${{ matrix.arch }}" = "arm64" ]; then
            CACHE_FILE="build/linux-arm64-full/CMakeCache.txt"
            test -f "$CACHE_FILE" || { echo "Missing CMake cache at $CACHE_FILE"; exit 1; }
            grep -q '^GGML_CPU_KLEIDIAI:BOOL=ON$' "$CACHE_FILE" || { echo "Kleidi is not enabled in arm64 build"; exit 1; }
          fi
      - name: Stage upload payload
        run: |
          OUT_DIR="bin/linux/${{ matrix.arch }}"
          PAYLOAD="artifact_payload"
          mkdir -p "$PAYLOAD"
          shopt -s nullglob
          if [ "${{ matrix.include_core }}" = "true" ]; then
            files=("$OUT_DIR"/*.so)
          else
            files=("$OUT_DIR"/${{ matrix.backend_glob }})
          fi
          [ "${#files[@]}" -gt 0 ] || { echo "No files staged for upload"; exit 1; }
          cp "${files[@]}" "$PAYLOAD"/
          ls -la "$PAYLOAD"
      - name: Upload
        uses: actions/upload-artifact@v4
        with:
          name: native_linux_${{ matrix.arch }}_${{ matrix.backend }}
          path: artifact_payload/*

  build-linux-hip:
    needs: resolve-tag
    runs-on: ubuntu-latest
    container: rocm/dev-ubuntu-22.04:6.1.2
    env:
      CCACHE_DIR: ${{ github.workspace }}/.ccache
      CCACHE_MAXSIZE: 5G
    steps:
      - name: Install Git
        run: |
          apt-get update
          DEBIAN_FRONTEND=noninteractive apt-get install -y git
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: recursive
      - name: Checkout llama.cpp ref
        if: ${{ github.event.inputs.llama_cpp_tag != 'submodule' }}
        uses: ./.github/actions/checkout-llama-ref
        with:
          tag: ${{ needs.resolve-tag.outputs.tag }}
          github_token: ${{ github.token }}
      - name: Install build deps
        run: |
          DEBIAN_FRONTEND=noninteractive apt-get install -y build-essential ccache ninja-build pkg-config python3 python3-pip rocblas-dev hipblas-dev
          python3 -m pip install --upgrade cmake
          cmake --version
      - name: Restore ccache
        uses: actions/cache@v4
        with:
          path: ${{ env.CCACHE_DIR }}
          key: ccache-linux-x64-hip-${{ github.run_id }}
          restore-keys: |
            ccache-linux-x64-hip-
      - name: Prime ccache
        run: |
          mkdir -p "${CCACHE_DIR}"
          ccache --max-size "${CCACHE_MAXSIZE}"
          ccache --zero-stats
      - name: Build
        run: python3 tools/build.py linux --arch x64 --backend hip
      - name: ccache stats
        if: always()
        run: ccache --show-stats
      - name: Validate Linux HIP artifacts
        run: |
          OUT_DIR="bin/linux/x64"
          test -f "$OUT_DIR/libggml-hip.so" || { echo "Missing $OUT_DIR/libggml-hip.so"; exit 1; }
      - name: Stage upload payload
        run: |
          OUT_DIR="bin/linux/x64"
          PAYLOAD="artifact_payload"
          mkdir -p "$PAYLOAD"
          cp "$OUT_DIR/libggml-hip.so" "$PAYLOAD"/
          ls -la "$PAYLOAD"
      - name: Upload
        uses: actions/upload-artifact@v4
        with:
          name: native_linux_x64_hip
          path: artifact_payload/*

  build-windows:
    needs: resolve-tag
    runs-on: ${{ matrix.runs_on }}
    env:
      CMAKE_C_COMPILER_LAUNCHER: sccache
      CMAKE_CXX_COMPILER_LAUNCHER: sccache
      CMAKE_CUDA_COMPILER_LAUNCHER: ""
    strategy:
      fail-fast: false
      matrix:
        include:
          - arch: x64
            vcpkg_triplet: x64-windows
            runs_on: windows-latest
            backend: vulkan
            include_core: true
            needs_cuda: false
            needs_openblas: false
            needs_vulkan: true
            backend_glob: "*ggml-vulkan*.dll"
          - arch: x64
            vcpkg_triplet: x64-windows
            runs_on: windows-latest
            backend: cuda
            include_core: false
            needs_cuda: true
            needs_openblas: false
            needs_vulkan: false
            backend_glob: "*ggml-cuda*.dll"
          - arch: x64
            vcpkg_triplet: x64-windows
            runs_on: windows-latest
            backend: blas
            include_core: false
            needs_cuda: false
            needs_openblas: true
            needs_vulkan: false
            backend_glob: "*ggml-blas*.dll"
          - arch: arm64
            vcpkg_triplet: arm64-windows
            runs_on: windows-11-arm
            backend: vulkan
            include_core: true
            needs_cuda: false
            needs_openblas: false
            needs_vulkan: true
            backend_glob: "*ggml-vulkan*.dll"
          - arch: arm64
            vcpkg_triplet: arm64-windows
            runs_on: windows-11-arm
            backend: blas
            include_core: false
            needs_cuda: false
            needs_openblas: true
            needs_vulkan: false
            backend_glob: "*ggml-blas*.dll"
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: recursive
      - name: Enable Git Long Paths
        run: git config --global core.longpaths true
      - name: Setup MSVC (x64)
        if: ${{ matrix.arch == 'x64' }}
        uses: ilammy/msvc-dev-cmd@v1
        with:
          arch: x64
      - name: Setup MSVC (arm64 cross)
        if: ${{ matrix.arch == 'arm64' }}
        uses: ilammy/msvc-dev-cmd@v1
        with:
          arch: arm64
      - name: Checkout llama.cpp ref
        if: ${{ github.event.inputs.llama_cpp_tag != 'submodule' }}
        uses: ./.github/actions/checkout-llama-ref
        with:
          tag: ${{ needs.resolve-tag.outputs.tag }}
          github_token: ${{ github.token }}
      - name: Install Ninja
        if: ${{ matrix.arch == 'x64' }}
        run: choco install ninja -y
      - name: Detect preinstalled CUDA Toolkit
        if: ${{ matrix.needs_cuda }}
        id: detect_cuda
        run: |
          $nvcc = $null
          $cmd = Get-Command nvcc.exe -ErrorAction SilentlyContinue
          if ($cmd) {
            $nvcc = $cmd.Source
          }
          if (-not $nvcc) {
            $candidates = Get-ChildItem "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA" -Directory -ErrorAction SilentlyContinue |
              Sort-Object Name -Descending |
              ForEach-Object { Join-Path $_.FullName "bin\nvcc.exe" }
            $nvcc = $candidates | Where-Object { Test-Path $_ } | Select-Object -First 1
          }
          if ($nvcc) {
            $cudaBin = Split-Path $nvcc -Parent
            Add-Content $env:GITHUB_PATH $cudaBin
            Add-Content $env:GITHUB_ENV "CUDA_PATH=$(Split-Path $cudaBin -Parent)"
            Add-Content $env:GITHUB_OUTPUT "found=true"
            Write-Host "Using preinstalled CUDA: $nvcc"
            & $nvcc --version
          } else {
            Add-Content $env:GITHUB_OUTPUT "found=false"
            Write-Host "No preinstalled CUDA detected."
          }
      - name: Install CUDA Toolkit (minimal components)
        if: ${{ matrix.needs_cuda && steps.detect_cuda.outputs.found != 'true' }}
        uses: ./third_party/llama.cpp/.github/actions/windows-setup-cuda
        with:
          cuda_version: '12.4'
      - name: Register CUDA in PATH
        if: ${{ matrix.needs_cuda }}
        run: |
          $cudaBin = Get-ChildItem "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA" -Directory -ErrorAction SilentlyContinue |
            Sort-Object Name -Descending |
            ForEach-Object { Join-Path $_.FullName "bin" } |
            Where-Object { Test-Path (Join-Path $_ "nvcc.exe") } |
            Select-Object -First 1
          if (-not $cudaBin) {
            throw "nvcc.exe not found after CUDA install"
          }
          Add-Content $env:GITHUB_PATH $cudaBin
          Add-Content $env:GITHUB_ENV "CUDA_PATH=$(Split-Path $cudaBin -Parent)"
          & (Join-Path $cudaBin "nvcc.exe") --version
      - name: Restore vcpkg cache
        if: ${{ matrix.needs_openblas }}
        id: vcpkg-cache
        uses: actions/cache/restore@v4
        with:
          path: |
            C:\vcpkg\downloads
            C:\vcpkg\packages
            C:\vcpkg\installed
          key: vcpkg-${{ runner.os }}-${{ matrix.vcpkg_triplet }}-${{ env.VCPKG_CACHE_VERSION }}
          restore-keys: |
            vcpkg-${{ runner.os }}-${{ matrix.vcpkg_triplet }}-
      - name: Install OpenBLAS (vcpkg)
        if: ${{ matrix.needs_openblas }}
        run: |
          $vcpkgRoot = "C:\vcpkg"
          if (-not (Test-Path $vcpkgRoot)) {
            git clone https://github.com/microsoft/vcpkg "$vcpkgRoot"
          }
          if (-not (Test-Path "$vcpkgRoot\vcpkg.exe")) {
            & "$vcpkgRoot\bootstrap-vcpkg.bat" -disableMetrics
          }
          $openblasLib = Join-Path $vcpkgRoot "installed\${{ matrix.vcpkg_triplet }}\lib\openblas.lib"
          if (-not (Test-Path $openblasLib)) {
            & "$vcpkgRoot\vcpkg.exe" install "openblas:${{ matrix.vcpkg_triplet }}"
          } else {
            Write-Host "OpenBLAS already present in cache: $openblasLib"
          }

          $pkgconfCandidates = @(
            (Join-Path $vcpkgRoot "installed\x64-windows\tools\pkgconf\pkg-config.exe"),
            (Join-Path $vcpkgRoot "installed\x64-windows\tools\pkgconf\pkgconf.exe")
          )
          $pkgconf = $pkgconfCandidates | Where-Object { Test-Path $_ } | Select-Object -First 1
          if (-not $pkgconf) {
            & "$vcpkgRoot\vcpkg.exe" install "pkgconf:x64-windows"
            $pkgconf = $pkgconfCandidates | Where-Object { Test-Path $_ } | Select-Object -First 1
          }
          if (-not $pkgconf) {
            throw "pkg-config executable not found in vcpkg tools"
          }
          Add-Content $env:GITHUB_PATH (Split-Path $pkgconf -Parent)
          Add-Content $env:GITHUB_ENV "PKG_CONFIG_EXECUTABLE=$pkgconf"
          Add-Content $env:GITHUB_ENV "VCPKG_ROOT=$vcpkgRoot"
      - name: Setup sccache
        uses: mozilla-actions/sccache-action@v0.0.9
      - name: Configure sccache
        run: |
          echo "SCCACHE_GHA_ENABLED=true" >> $env:GITHUB_ENV
      - name: Install Vulkan SDK
        if: ${{ matrix.needs_vulkan }}
        run: |
          $ver = "1.4.313.2"
          curl.exe -o $env:RUNNER_TEMP/VulkanSDK-Installer.exe -L "https://sdk.lunarg.com/sdk/download/$ver/windows/vulkansdk-windows-X64-$ver.exe"
          & "$env:RUNNER_TEMP\VulkanSDK-Installer.exe" --accept-licenses --default-answer --confirm-command install
          Add-Content $env:GITHUB_ENV "VULKAN_SDK=C:\VulkanSDK\$ver"
          Add-Content $env:GITHUB_PATH "C:\VulkanSDK\$ver\Bin"
      - name: Build
        run: python tools/build.py windows --arch ${{ matrix.arch }} --backend ${{ matrix.backend }}
      - name: Validate Windows backend artifacts
        run: |
          $out = "bin/windows/${{ matrix.arch }}"
          if (-not (Get-ChildItem $out -Filter "${{ matrix.backend_glob }}" -ErrorAction SilentlyContinue | Select-Object -First 1)) {
            throw "Missing backend DLL '${{ matrix.backend_glob }}' in $out"
          }
          if ("${{ matrix.backend }}" -eq "cuda") {
            if (-not (Get-ChildItem $out -Filter "cudart64_*.dll" -ErrorAction SilentlyContinue | Select-Object -First 1)) {
              throw "Missing CUDA runtime dependency (cudart64_*.dll) in $out"
            }
            if (-not (Get-ChildItem $out -Filter "cublas64_*.dll" -ErrorAction SilentlyContinue | Select-Object -First 1)) {
              throw "Missing CUDA runtime dependency (cublas64_*.dll) in $out"
            }
          }
          if ("${{ matrix.backend }}" -eq "blas") {
            if (-not (Get-ChildItem $out -Filter "openblas*.dll" -ErrorAction SilentlyContinue | Select-Object -First 1)) {
              throw "Missing BLAS runtime dependency (openblas*.dll) in $out"
            }
          }
          if ("${{ matrix.include_core }}" -eq "true") {
            if (-not (Get-ChildItem $out -Filter "*llamadart*.dll" -ErrorAction SilentlyContinue | Select-Object -First 1)) {
              throw "Missing core wrapper DLL in $out"
            }
          }
          if ("${{ matrix.arch }}" -eq "arm64") {
            $cache = "build/wa64/CMakeCache.txt"
            if (-not (Test-Path $cache)) {
              throw "Missing CMake cache at $cache"
            }
            if (-not (Select-String -Path $cache -Pattern '^GGML_CPU_KLEIDIAI:BOOL=ON$' -Quiet)) {
              throw "Kleidi is not enabled in windows arm64 build"
            }
          }
      - name: Stage upload payload
        run: |
          $out = "bin/windows/${{ matrix.arch }}"
          $payload = "artifact_payload"
          New-Item -ItemType Directory -Force -Path $payload | Out-Null

          if ("${{ matrix.include_core }}" -eq "true") {
            $files = Get-ChildItem $out -Filter "*.dll" -ErrorAction Stop
          } else {
            $files = @(
              Get-ChildItem $out -Filter "${{ matrix.backend_glob }}" -ErrorAction Stop
            )
            if ("${{ matrix.backend }}" -eq "cuda") {
              $files += Get-ChildItem $out -Filter "cudart64_*.dll" -ErrorAction SilentlyContinue
              $files += Get-ChildItem $out -Filter "cublas64_*.dll" -ErrorAction SilentlyContinue
              $files += Get-ChildItem $out -Filter "cublasLt64_*.dll" -ErrorAction SilentlyContinue
            }
            if ("${{ matrix.backend }}" -eq "blas") {
              $files += Get-ChildItem $out -Filter "openblas*.dll" -ErrorAction SilentlyContinue
            }
            $files = $files | Sort-Object FullName -Unique
          }
          if (-not $files) {
            throw "No files staged for upload"
          }
          foreach ($f in $files) {
            Copy-Item $f.FullName -Destination $payload -Force
          }
          Get-ChildItem $payload
      - name: Upload
        uses: actions/upload-artifact@v4
        with:
          name: native_windows_${{ matrix.arch }}_${{ matrix.backend }}
          path: artifact_payload/*
      - name: Save vcpkg cache
        if: ${{ always() && matrix.needs_openblas && steps.vcpkg-cache.outputs.cache-hit != 'true' }}
        uses: actions/cache/save@v4
        with:
          path: |
            C:\vcpkg\downloads
            C:\vcpkg\packages
            C:\vcpkg\installed
          key: vcpkg-${{ runner.os }}-${{ matrix.vcpkg_triplet }}-${{ env.VCPKG_CACHE_VERSION }}

  package-and-release:
    needs: [resolve-tag, build-android, build-apple, build-linux, build-linux-hip, build-windows]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: recursive
      - name: Checkout llama.cpp ref
        if: ${{ github.event.inputs.llama_cpp_tag != 'submodule' }}
        uses: ./.github/actions/checkout-llama-ref
        with:
          tag: ${{ needs.resolve-tag.outputs.tag }}
          github_token: ${{ github.token }}
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
      - name: Prepare release assets
        run: |
          mkdir -p release_assets
          mkdir -p bundles

          for dir in artifacts/native_*; do
            [ -d "$dir" ] || continue
            name="$(basename "$dir")"

            bundle=""
            if [[ "$name" =~ ^native_windows_(x64|arm64)(_.+)?$ ]]; then
              bundle="windows-${BASH_REMATCH[1]}"
            elif [[ "$name" =~ ^native_linux_(x64|arm64)(_.+)?$ ]]; then
              bundle="linux-${BASH_REMATCH[1]}"
            elif [[ "$name" =~ ^native_android_(arm64-v8a|x86_64)(_.+)?$ ]]; then
              if [ "${BASH_REMATCH[1]}" = "arm64-v8a" ]; then
                bundle="android-arm64"
              else
                bundle="android-x64"
              fi
            elif [[ "$name" = "native_apple_macos-arm64" ]]; then
              bundle="macos-arm64"
            elif [[ "$name" = "native_apple_macos-x86_64" ]]; then
              bundle="macos-x86_64"
            elif [[ "$name" = "native_apple_ios-device-arm64" ]]; then
              bundle="ios-arm64"
            elif [[ "$name" = "native_apple_ios-sim-arm64" ]]; then
              bundle="ios-arm64-sim"
            elif [[ "$name" = "native_apple_ios-sim-x86_64" ]]; then
              bundle="ios-x86_64-sim"
            else
              echo "Skipping unknown artifact directory: $name"
              continue
            fi

            out_dir="bundles/${bundle}"
            mkdir -p "$out_dir"
            while IFS= read -r src; do
              [ -n "$src" ] || continue
              cp -f "$src" "${out_dir}/$(basename "$src")"
            done < <(find "$dir" -maxdepth 1 -type f \( -name '*.dll' -o -name '*.dylib' -o -name '*.so' \) | sort)
          done

          for bundle_dir in bundles/*; do
            [ -d "$bundle_dir" ] || continue
            if ! find "$bundle_dir" -maxdepth 1 -type f -print -quit | grep -q .; then
              echo "Skipping empty bundle directory: $bundle_dir"
              continue
            fi
            bundle_name="$(basename "$bundle_dir")"
            archive="llamadart-native-${bundle_name}-${{ needs.resolve-tag.outputs.tag }}.tar.gz"
            tar -czf "release_assets/${archive}" -C "$bundle_dir" .
          done

          mkdir -p \
            headers_bundle/libllamadart \
            headers_bundle/llama_cpp/include \
            headers_bundle/llama_cpp/ggml/include \
            headers_bundle/llama_cpp/tools/mtmd
          cp src/llama_dart_wrapper.h headers_bundle/libllamadart/
          shopt -s nullglob
          for hdr in third_party/llama.cpp/include/*.{h,hpp}; do
            cp "$hdr" headers_bundle/llama_cpp/include/
          done
          for hdr in third_party/llama.cpp/ggml/include/*.{h,hpp}; do
            cp "$hdr" headers_bundle/llama_cpp/ggml/include/
          done
          for hdr in third_party/llama.cpp/tools/mtmd/*.{h,hpp}; do
            cp "$hdr" headers_bundle/llama_cpp/tools/mtmd/
          done
          HEADER_ARCHIVE="llamadart-native-headers-${{ needs.resolve-tag.outputs.tag }}.tar.gz"
          tar -czf "release_assets/${HEADER_ARCHIVE}" -C headers_bundle libllamadart llama_cpp

          ls -la release_assets
          test -n "$(find release_assets -maxdepth 1 -type f -print -quit)"

      - name: Generate manifest + checksums
        run: |
          chmod +x scripts/generate_assets_manifest.sh
          scripts/generate_assets_manifest.sh \
            "${{ needs.resolve-tag.outputs.tag }}" \
            release_assets \
            release_assets/assets.json \
            release_assets/SHA256SUMS

      - name: Create release
        if: ${{ github.event.inputs.publish_release == 'true' }}
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ needs.resolve-tag.outputs.tag }}
          name: ${{ needs.resolve-tag.outputs.tag }}
          files: release_assets/*
          prerelease: false

  update-llama-submodule:
    needs: [resolve-tag, package-and-release]
    if: ${{ github.event.inputs.publish_release == 'true' && needs.package-and-release.result == 'success' }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: recursive
      - name: Move llama.cpp submodule to released tag
        uses: ./.github/actions/checkout-llama-ref
        with:
          tag: ${{ needs.resolve-tag.outputs.tag }}
          github_token: ${{ github.token }}
      - name: Commit and push submodule update
        run: |
          if git diff --quiet -- third_party/llama.cpp; then
            echo "llama.cpp submodule already at ${{ needs.resolve-tag.outputs.tag }}"
            exit 0
          fi
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add third_party/llama.cpp
          git commit -m "chore: bump llama.cpp submodule to ${{ needs.resolve-tag.outputs.tag }}"
          git push origin HEAD:${{ github.ref_name }}
